{
  
    
        "post0": {
            "title": "SimCLR - Contrastive Learning of visual representations",
            "content": "Find out here. Planning on releasing some example code in Pytorch soon! .",
            "url": "https://arnaudautef.com/deep%20learning/computer%20vision/contrastive%20learning/2021/11/08/simclr.html",
            "relUrl": "/deep%20learning/computer%20vision/contrastive%20learning/2021/11/08/simclr.html",
            "date": " • Nov 8, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Are regularized MLPs state-of-the-art on tabular data?",
            "content": "Find out here .",
            "url": "https://arnaudautef.com/deep%20learning/2021/10/10/regularized-mlps.html",
            "relUrl": "/deep%20learning/2021/10/10/regularized-mlps.html",
            "date": " • Oct 10, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Past reading group talks",
            "content": "I run Sisu’s Machine Learning Reading group, and contribute to it regularly. Here are my most recent public presentations: . The LassoNet | Simple Bayesian Algorithms for Best Arm Identification | The R-learner | The Synthetic Controls method |",
            "url": "https://arnaudautef.com/2021/07/03/first-post.html",
            "relUrl": "/2021/07/03/first-post.html",
            "date": " • Jul 3, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://arnaudautef.com/2020/01/14/test-markdown-post.html",
            "relUrl": "/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Hello! My name is Arnaud Autef and welcome to my personal website. . I post about Machine Learning, Statistics and Optimization. Some topics that I follow more closely are Reinforcement and Bandit Learning, Natural Language Processing, the big “representation learning” bucket in Deep Learning (e.g: constrastive learning), and Bayesian Deep Learning. . I use the fastpages website template to make it easy for readers to leave comments, and I am very much looking forward to feedback there! If comments are not for you, feel free to send me an email (firstname.lastname at gmail). . Some words about my background . I am a Machine Learning Engineer at Sisu Data. In Sisu’s ML team, I work on machine learning systems that must scale to billion row datasets with hundreds of thousands of predictive features, producing results in less than minutes. So far, the algorithms I have developed use tools from high-dimensional statistics, optimization and information theory. As our roadmap moves rapidly, I expect future projects to involve techniques from the recommendations sytems community and some Deep Learning. . In my work at Sisu, I own Machine Learning projects end-to-end: from literature review, to prototyping in Python, and productionization in Rust (with some extra database and frontend work sometimes, to expose my algorithms to Sisu customers faster if other engineering teams are stretched). I am also very lucky to have had Vladimir Feinberg as my mentor there, do check out his amazing blog. . In parallel to IC work, I am in charge of the Statistics phone screen (which I designed) and the Probability interview for Machine Learning Engineer candidates. I am mentoring our latest team member, and leading Sisu’s Machine Learning reading group. I encourage you to check out paper reviews from our talented team members there. . Prior to joining Sisu, I was a MSc student in Management Science and Engineering at Stanford University, focusing my coursework on Statistics, Optimization and Deep Learning. . During my time at Stanford, I spent 6 months building a recommendation system in Jure Leskovec’s SNAP research group, as a Research Assistant. I was a teaching assistant for two classes: CS224N with Prof. Christopher Manning (Natural Language Processing with Deep Learning) and CS236 (Deep Generative Models) with Prof. Stefano Ermon. . I was also very fortunate to spend 6 months doing research on Information Direction Sampling (IDS) for the Assortment Optimization problem, supervised by Dr. Xiuyuan Lu and Professor Benjamin Van Roy. I first experimented with ideas around a “greedy” version of IDS, presented my findings in a reading group talk and wrote them up a report. I came back to the topic in 2020 while working at Sisu, inspired by a lecture from Tore Lattimore on IDS: I obtained two theoretical results on the simple form of IDS solutions with independent item-level information gains, and information theoretic regret bounds for Thompson Sampling on the assortment optimization problem. See there for an overview of those latest findings, and happy to answer questions about proofs details. . Finally, during my summer 2019 at Stanford, I interned at Microsoft in Redmond and used statistics and bandit learning to improve hardware failures mitigation in Azure Compute. . Before Stanford, I interned for 5 months at IBM Research Singapore with Dr. Shiau Hong Lim. We published our research in Reinforcement Learning theory at ICML 2019, where I presented our paper “Kernel based reinforcement learning in Robust Markov Decision Processes”. . Prior to that, I earned a MSc in Applied Mathematics from the Ecole Polytechnique (Paris), where my coursework focused on Probability, Statistics, Optimization and Machine Learning. . Find me on . Github | Twitter | Linkedin | . Resume . here | .",
          "url": "https://arnaudautef.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://arnaudautef.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}